{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2 - Limpieza de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sebastian Aristondo 20880  \n",
    "- Diego Franco 20240  \n",
    "- Manuel Archila 161250  \n",
    "- Juan Diego Avila 20090  \n",
    "- Daniel Gonzalez Carrillo 20293  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from scipy import ndimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('meta_train_with_vertebrae.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Slice</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>SliceThickness</th>\n",
       "      <th>ImagePositionPatient_x</th>\n",
       "      <th>ImagePositionPatient_y</th>\n",
       "      <th>ImagePositionPatient_z</th>\n",
       "      <th>SliceRatio</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-52.308</td>\n",
       "      <td>-27.712</td>\n",
       "      <td>7.282</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-52.308</td>\n",
       "      <td>-27.712</td>\n",
       "      <td>6.657</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-52.308</td>\n",
       "      <td>-27.712</td>\n",
       "      <td>6.032</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-52.308</td>\n",
       "      <td>-27.712</td>\n",
       "      <td>5.407</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-52.308</td>\n",
       "      <td>-27.712</td>\n",
       "      <td>4.782</td>\n",
       "      <td>0.018657</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  Slice  ImageHeight  ImageWidth  SliceThickness  \\\n",
       "0  1.2.826.0.1.3680043.10001      1          512         512           0.625   \n",
       "1  1.2.826.0.1.3680043.10001      2          512         512           0.625   \n",
       "2  1.2.826.0.1.3680043.10001      3          512         512           0.625   \n",
       "3  1.2.826.0.1.3680043.10001      4          512         512           0.625   \n",
       "4  1.2.826.0.1.3680043.10001      5          512         512           0.625   \n",
       "\n",
       "   ImagePositionPatient_x  ImagePositionPatient_y  ImagePositionPatient_z  \\\n",
       "0                 -52.308                 -27.712                   7.282   \n",
       "1                 -52.308                 -27.712                   6.657   \n",
       "2                 -52.308                 -27.712                   6.032   \n",
       "3                 -52.308                 -27.712                   5.407   \n",
       "4                 -52.308                 -27.712                   4.782   \n",
       "\n",
       "   SliceRatio  C1  C2  C3  C4  C5  C6  C7  \n",
       "0    0.003731   0   0   0   0   0   0   0  \n",
       "1    0.007463   0   0   0   0   0   0   0  \n",
       "2    0.011194   0   0   0   0   0   0   0  \n",
       "3    0.014925   0   0   0   0   0   0   0  \n",
       "4    0.018657   0   0   0   0   0   0   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de volúmenes para 3DCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "    # Extraer el número de la cadena (por ejemplo, \"10\" de \"10.dcm\")\n",
    "    return int(filename.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(path):\n",
    "    # Obtener la lista de nombres de archivos de imágenes\n",
    "    image_files = os.listdir(path)\n",
    "    image_files.sort(key=extract_number)  # Asegura un orden adecuado\n",
    "    \n",
    "    # Inicializar una lista para almacenar los volúmenes 3D\n",
    "    volumes = []\n",
    "\n",
    "    # Leer y apilar las imágenes en un volumen 3D\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(path, image_file)\n",
    "        dicom_data = pydicom.dcmread(image_path)\n",
    "        image = apply_voi_lut(dicom_data.pixel_array, dicom_data)\n",
    "        volumes.append(image)\n",
    "\n",
    "    # Convertir la lista de volúmenes a un arreglo NumPy 3D\n",
    "    volumes_array = np.stack(volumes, axis=-1)\n",
    "\n",
    "    # Normalizar los valores de píxeles en el rango [0, 1]\n",
    "    # Esto puede variar dependiendo de la información específica de las imágenes DICOM\n",
    "    volumes_array = (volumes_array - np.min(volumes_array)) / (np.max(volumes_array) - np.min(volumes_array))\n",
    "    return volumes_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    min = -1000\n",
    "    max = 400\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 300\n",
    "    desired_width = 256\n",
    "    desired_height = 256\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scan(path):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    # Read scan\n",
    "    volume = read_images(path)\n",
    "    # Normalize\n",
    "    volume = normalize(volume)\n",
    "    # Resize width, height and depth\n",
    "    volume = resize_volume(volume)\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_29716\\1781923139.py:21: RuntimeWarning: invalid value encountered in divide\n",
      "  volumes_array = (volumes_array - np.min(volumes_array)) / (np.max(volumes_array) - np.min(volumes_array))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Daniel\\Main\\UVG\\Semestre VIII\\Data science\\Proyecto2\\Proyecto2_limpieza.ipynb Cell 13\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m patient \u001b[39min\u001b[39;00m patients:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     patient_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, patient)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     volumes \u001b[39m=\u001b[39m process_scan(patient_dir)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     output_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvolumes/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m patient \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     np\u001b[39m.\u001b[39msave(output_file, volumes)\n",
      "\u001b[1;32mc:\\Users\\Daniel\\Main\\UVG\\Semestre VIII\\Data science\\Proyecto2\\Proyecto2_limpieza.ipynb Cell 13\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m volume \u001b[39m=\u001b[39m normalize(volume)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Resize width, height and depth\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m volume \u001b[39m=\u001b[39m resize_volume(volume)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mreturn\u001b[39;00m volume\n",
      "\u001b[1;32mc:\\Users\\Daniel\\Main\\UVG\\Semestre VIII\\Data science\\Proyecto2\\Proyecto2_limpieza.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m height_factor \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m height\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Rotate\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m img \u001b[39m=\u001b[39m ndimage\u001b[39m.\u001b[39;49mrotate(img, \u001b[39m90\u001b[39;49m, reshape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Resize across z-axis\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m img \u001b[39m=\u001b[39m ndimage\u001b[39m.\u001b[39mzoom(img, (width_factor, height_factor, depth_factor), order\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Main\\UVG\\Semestre VIII\\Data science\\Proyecto2\\myenv\\lib\\site-packages\\scipy\\ndimage\\_interpolation.py:957\u001b[0m, in \u001b[0;36mrotate\u001b[1;34m(input, angle, axes, reshape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    955\u001b[0m         ia \u001b[39m=\u001b[39m input_arr[coordinates]\n\u001b[0;32m    956\u001b[0m         oa \u001b[39m=\u001b[39m output[coordinates]\n\u001b[1;32m--> 957\u001b[0m         affine_transform(ia, rot_matrix, offset, out_plane_shape,\n\u001b[0;32m    958\u001b[0m                          oa, order, mode, cval, prefilter)\n\u001b[0;32m    960\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Main\\UVG\\Semestre VIII\\Data science\\Proyecto2\\myenv\\lib\\site-packages\\scipy\\ndimage\\_interpolation.py:614\u001b[0m, in \u001b[0;36maffine_transform\u001b[1;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    611\u001b[0m     _nd_image\u001b[39m.\u001b[39mzoom_shift(filtered, matrix, offset\u001b[39m/\u001b[39mmatrix, output, order,\n\u001b[0;32m    612\u001b[0m                          mode, cval, npad, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    613\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 614\u001b[0m     _nd_image\u001b[39m.\u001b[39;49mgeometric_transform(filtered, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, matrix, offset,\n\u001b[0;32m    615\u001b[0m                                   output, order, mode, cval, npad, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    616\u001b[0m                                   \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    617\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "root = \"train_images\"\n",
    "save_dir = \"volumes\"\n",
    "patients = os.listdir(root)\n",
    "count = 0\n",
    "for patient in patients:\n",
    "    patient_dir = os.path.join(root, patient)\n",
    "    volumes = process_scan(patient_dir)\n",
    "    output_file = \"volumes/\" + patient + \".npy\"\n",
    "    np.save(output_file, volumes)\n",
    "    #if count >= 10:\n",
    "    #    break\n",
    "    #count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizó una lectura de todas las imágenes en formato dicom que se pudieron descargar del dataset original. Luego, se leyeron y se convirtió en un volumen de numpy para cada paciente. Estos volúmenes se guardaron en un archivo .npy para su posterior uso en la red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicom a JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The length of the pixel data in the dataset (392484 bytes) doesn't match the expected length (524288 bytes). The dataset may be corrupted or there may be an issue with the pixel data handler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Daniel\\Main\\UVG\\Semestre VIII\\Data science\\Proyecto2\\Proyecto2_limpieza.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X44sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m ruta_archivo_dicom \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(carpeta_dicom, archivo_dicom)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X44sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m imagen_dicom \u001b[39m=\u001b[39m pydicom\u001b[39m.\u001b[39mdcmread(ruta_archivo_dicom)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X44sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m gray_image \u001b[39m=\u001b[39m imagen_dicom\u001b[39m.\u001b[39;49mpixel_array\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X44sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Normalizar la imagen en escala de grises\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Daniel/Main/UVG/Semestre%20VIII/Data%20science/Proyecto2/Proyecto2_limpieza.ipynb#X44sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m normalized_gray_image \u001b[39m=\u001b[39m gray_image \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mmax(gray_image)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Main\\UVG\\Semestre VIII\\Data science\\Proyecto2\\myenv\\lib\\site-packages\\pydicom\\dataset.py:1955\u001b[0m, in \u001b[0;36mDataset.pixel_array\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1940\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m   1941\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpixel_array\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumpy.ndarray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1942\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the pixel data as a :class:`numpy.ndarray`.\u001b[39;00m\n\u001b[0;32m   1943\u001b[0m \n\u001b[0;32m   1944\u001b[0m \u001b[39m    .. versionchanged:: 1.4\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1953\u001b[0m \u001b[39m        :class:`numpy.ndarray`.\u001b[39;00m\n\u001b[0;32m   1954\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1955\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_pixel_data()\n\u001b[0;32m   1956\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(\u001b[39m\"\u001b[39m\u001b[39mnumpy.ndarray\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pixel_array)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Main\\UVG\\Semestre VIII\\Data science\\Proyecto2\\myenv\\lib\\site-packages\\pydicom\\dataset.py:1512\u001b[0m, in \u001b[0;36mDataset.convert_pixel_data\u001b[1;34m(self, handler_name)\u001b[0m\n\u001b[0;32m   1510\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_pixel_data_using_handler(handler_name)\n\u001b[0;32m   1511\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1512\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_pixel_data_without_handler()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Main\\UVG\\Semestre VIII\\Data science\\Proyecto2\\myenv\\lib\\site-packages\\pydicom\\dataset.py:1624\u001b[0m, in \u001b[0;36mDataset._convert_pixel_data_without_handler\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1615\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pixel_id \u001b[39m=\u001b[39m {}\n\u001b[0;32m   1617\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m   1618\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mUnable to decode the pixel data using the following handlers: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1619\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease see the list of supported Transfer Syntaxes in the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1622\u001b[0m     \u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(hh) \u001b[39mfor\u001b[39;00m hh \u001b[39min\u001b[39;00m available_handlers]))\n\u001b[0;32m   1623\u001b[0m )\n\u001b[1;32m-> 1624\u001b[0m \u001b[39mraise\u001b[39;00m last_exception\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Main\\UVG\\Semestre VIII\\Data science\\Proyecto2\\myenv\\lib\\site-packages\\pydicom\\dataset.py:1604\u001b[0m, in \u001b[0;36mDataset._convert_pixel_data_without_handler\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1602\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m available_handlers:\n\u001b[0;32m   1603\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1604\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_pixel_data_conversion(handler)\n\u001b[0;32m   1605\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1606\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Main\\UVG\\Semestre VIII\\Data science\\Proyecto2\\myenv\\lib\\site-packages\\pydicom\\dataset.py:1631\u001b[0m, in \u001b[0;36mDataset._do_pixel_data_conversion\u001b[1;34m(self, handler)\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Do the actual data conversion using the given handler.\"\"\"\u001b[39;00m\n\u001b[0;32m   1629\u001b[0m \u001b[39m# Use the handler to get a 1D numpy array of the pixel data\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[39m# Will raise an exception if no pixel data element\u001b[39;00m\n\u001b[1;32m-> 1631\u001b[0m arr \u001b[39m=\u001b[39m handler\u001b[39m.\u001b[39;49mget_pixeldata(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m   1632\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pixel_array \u001b[39m=\u001b[39m reshape_pixel_array(\u001b[39mself\u001b[39m, arr)\n\u001b[0;32m   1634\u001b[0m \u001b[39m# Some handler/transfer syntax combinations may need to\u001b[39;00m\n\u001b[0;32m   1635\u001b[0m \u001b[39m#   convert the color space from YCbCr to RGB\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\Main\\UVG\\Semestre VIII\\Data science\\Proyecto2\\myenv\\lib\\site-packages\\pydicom\\pixel_data_handlers\\numpy_handler.py:221\u001b[0m, in \u001b[0;36mget_pixeldata\u001b[1;34m(ds, read_only)\u001b[0m\n\u001b[0;32m    217\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    218\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe odd length pixel data is missing a trailing padding byte\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         )\n\u001b[0;32m    220\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 221\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe length of the pixel data in the dataset (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m bytes) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mdoesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match the expected length (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m bytes). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe dataset may be corrupted or there may be an issue \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwith the pixel data handler.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    226\u001b[0m             \u001b[39m.\u001b[39mformat(actual_length, padded_expected_len)\n\u001b[0;32m    227\u001b[0m         )\n\u001b[0;32m    228\u001b[0m \u001b[39melif\u001b[39;00m actual_length \u001b[39m>\u001b[39m padded_expected_len:\n\u001b[0;32m    229\u001b[0m     \u001b[39m# PS 3.5, Section 8.1.1\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    231\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe length of the pixel data in the dataset (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m bytes) indicates \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mit contains excess padding. \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m bytes will be removed from the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mend of the data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m         \u001b[39m.\u001b[39mformat(actual_length, actual_length \u001b[39m-\u001b[39m expected_len)\n\u001b[0;32m    235\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The length of the pixel data in the dataset (392484 bytes) doesn't match the expected length (524288 bytes). The dataset may be corrupted or there may be an issue with the pixel data handler."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "# Ruta de la carpeta con archivos DICOM\n",
    "carpeta_dicom_base = \"train_images\"\n",
    "carpeta_jpg_base = \"imagenes_train\"\n",
    "\n",
    "# Obtener una lista de carpetas en la carpeta base\n",
    "carpetas = [f for f in os.listdir(carpeta_dicom_base) if os.path.isdir(os.path.join(carpeta_dicom_base, f))]\n",
    "\n",
    "# Iterar sobre cada carpeta y procesar los archivos DICOM\n",
    "for carpeta in carpetas:\n",
    "    carpeta_dicom = os.path.join(carpeta_dicom_base, carpeta)\n",
    "    carpeta_jpg = os.path.join(carpeta_jpg_base, carpeta)\n",
    "\n",
    "    # Obtener lista de archivos DICOM en la carpeta\n",
    "    archivos_dicom = [f for f in os.listdir(carpeta_dicom) if f.endswith('.dcm')]\n",
    "\n",
    "    # Crear un objeto en memoria para almacenar el archivo ZIP\n",
    "    zip_memory = io.BytesIO()\n",
    "    with zipfile.ZipFile(zip_memory, \"a\", zipfile.ZIP_DEFLATED, False) as zipf:\n",
    "        # Iterar sobre los archivos DICOM y convertirlos a JPG y agregarlos al archivo ZIP\n",
    "        for archivo_dicom in archivos_dicom:\n",
    "            ruta_archivo_dicom = os.path.join(carpeta_dicom, archivo_dicom)\n",
    "            imagen_dicom = pydicom.dcmread(ruta_archivo_dicom)\n",
    "\n",
    "            gray_image = imagen_dicom.pixel_array\n",
    "\n",
    "            # Normalizar la imagen en escala de grises\n",
    "            normalized_gray_image = gray_image / np.max(gray_image)\n",
    "\n",
    "            # Crear una imagen RGB a partir de la imagen en escala de grises\n",
    "            # Asignar el valor de intensidad de grises a los canales R, G y B\n",
    "            rgb_image = cv2.cvtColor((normalized_gray_image * 255).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            # Convertir la imagen en formato JPG en memoria\n",
    "            img_memory = io.BytesIO()\n",
    "            Image.fromarray(rgb_image).save(img_memory, format='JPEG')\n",
    "            img_memory.seek(0)\n",
    "\n",
    "            # Agregar la imagen al archivo ZIP\n",
    "            nombre_archivo_jpg = os.path.join(carpeta, archivo_dicom.replace('.dcm', '.jpg'))\n",
    "            zipf.writestr(nombre_archivo_jpg, img_memory.read())\n",
    "\n",
    "    # Guardar el archivo ZIP en disco\n",
    "    with open(f\"{carpeta_jpg}.zip\", \"wb\") as zip_file:\n",
    "        zip_file.write(zip_memory.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se convirtieron todas las imágenes de formato dicom a jpg, para poder utilizarlas en la red neuronal que fue un híbrido de EfficientNet y GRU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'imagenes_train'\n",
    "image_files = os.listdir(path)\n",
    "image_files = [x.split('.zip')[0] for x in image_files]\n",
    "\n",
    "df = pd.read_csv('train.csv', encoding='utf-8')\n",
    "\n",
    "condicion = df[\"StudyInstanceUID\"].isin(image_files)\n",
    "\n",
    "df_filta = df[condicion]\n",
    "\n",
    "df_filta.to_csv('train_filtrado_images.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que se realizó acá fue un filtrado del dataset original de train, para contener solo los pacientes existentes. Esto se realizó tanto para los volúmenes, como para las imágenes en jpg."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
